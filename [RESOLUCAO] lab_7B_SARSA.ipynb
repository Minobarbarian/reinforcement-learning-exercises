{"cells":[{"cell_type":"markdown","source":["# IMD1103 - Aprendizado por Reforço"],"metadata":{"id":"X-XapzRBJR-9"}},{"cell_type":"markdown","source":["### Professor: Dr. Leonardo Enzo Brito da Silva"],"metadata":{"id":"zZt3AoYhJX7G"}},{"cell_type":"markdown","source":["### Aluno: João Antonio Costa Paiva Chagas"],"metadata":{"id":"X87NbdQ8JZmn"}},{"cell_type":"markdown","metadata":{"id":"hf0af9vLqLW3"},"source":["# Laboratório 7B: Sarsa (CliffWalking)"]},{"cell_type":"markdown","metadata":{"id":"f3ahVih93jpQ"},"source":["## Importações"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtRypzNFEb3t"},"outputs":[],"source":["# Instala os pacotes necessários:\n","# - gymnasium[toy-text]: inclui ambientes simples como FrozenLake, Taxi, etc.\n","!pip install gymnasium[toy-text]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FTh_QK47EfwM"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import gymnasium as gym\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","from IPython.display import Image\n","import matplotlib.patches as patches\n","from typing import Dict, Tuple, List, Optional\n","from matplotlib.collections import LineCollection"]},{"cell_type":"markdown","source":["## Armazenamento"],"metadata":{"id":"ItBdrnoWTFNc"}},{"cell_type":"code","source":["output_dir = \"resultados_plots\"\n","os.makedirs(output_dir, exist_ok=True)"],"metadata":{"id":"_QmK9F3GTE_g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLfMlW3VqLW5"},"source":["## Funções auxiliares para visualização"]},{"cell_type":"code","source":["def plotar_comparacao_metricas(\n","    results: Dict[str, Dict[str, list]],\n","    titulo_prefixo: str,\n","    janela: int = 100,\n","    save_path: Optional[str] = None\n",") -> None:\n","    \"\"\"\n","    Plota a comparação de métricas (tamanho e retorno) de múltiplos\n","    experimentos em uma única figura.\n","    \"\"\"\n","    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 8), sharex=True)\n","    sns.set_palette(\"viridis\", n_colors=len(results)) # Optional: color palette\n","\n","    # Plot 1 – Tamanho do episódio\n","    for label, data in results.items():\n","        df = pd.DataFrame({'tamanho': data['T']})\n","        tamanho_ma = df['tamanho'].rolling(window=janela).mean()\n","        sns.lineplot(x=tamanho_ma.index, y=tamanho_ma, ax=axs[0], label=label)\n","\n","    axs[0].set_title(f'{titulo_prefixo} - Tamanho do Episódio')\n","    axs[0].set_ylabel(f'Passos por Episódio (Média Móvel {janela})')\n","    axs[0].legend()\n","    axs[0].grid()\n","\n","    # Plot 2 – Retorno\n","    for label, data in results.items():\n","        df = pd.DataFrame({'retorno': data['G']})\n","        retorno_ma = df['retorno'].rolling(window=janela).mean()\n","        sns.lineplot(x=retorno_ma.index, y=retorno_ma, ax=axs[1], label=label)\n","\n","    axs[1].set_title(f'{titulo_prefixo} - Retorno do Episódio')\n","    axs[1].set_xlabel('Episódio')\n","    axs[1].set_ylabel(f'Recompensa Total (Média Móvel {janela})')\n","    axs[1].legend()\n","    axs[1].grid()\n","\n","    plt.tight_layout()\n","    if save_path:\n","        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        print(f\"Plot de comparação salvo em: {save_path}\")\n","    else:\n","        plt.show()"],"metadata":{"id":"DnRwVcu2HGKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plotar_metricas_single(\n","    episodio_len: list[int],\n","    episodio_return: list[float],\n","    titulo: str,\n","    janela: int = 100,\n","    save_path: Optional[str] = None\n",") -> None:\n","    \"\"\"\n","    Usa Pandas + Seaborn para plotar as métricas de uma única execução.\n","    \"\"\"\n","    df = pd.DataFrame({\n","        'episodio': np.arange(len(episodio_len)),\n","        'tamanho': episodio_len,\n","        'retorno': episodio_return\n","    })\n","\n","    df['tamanho_ma'] = df['tamanho'].rolling(window=janela).mean()\n","    df['retorno_ma'] = df['retorno'].rolling(window=janela).mean()\n","\n","    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 8), sharex=True)\n","    fig.suptitle(titulo, fontsize=16)\n","\n","    # Plot 1 – Tamanho do episódio\n","    sns.lineplot(data=df, x='episodio', y='tamanho', ax=axs[0], label='Tamanho do Episódio', alpha=0.3)\n","    sns.lineplot(data=df, x='episodio', y='tamanho_ma', ax=axs[0], label=f'Média móvel ({janela})')\n","    axs[0].set_ylabel('Passos por Episódio')\n","    axs[0].legend()\n","    axs[0].grid()\n","\n","    # Plot 2 – Retorno\n","    sns.lineplot(data=df, x='episodio', y='retorno', ax=axs[1], label='Retorno do Episódio', color='orange', alpha=0.3)\n","    sns.lineplot(data=df, x='episodio', y='retorno_ma', ax=axs[1], label=f'Média móvel ({janela})', color='red')\n","    axs[1].set_xlabel('Episódio')\n","    axs[1].set_ylabel('Recompensa Total')\n","    axs[1].legend()\n","    axs[1].grid()\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle\n","    if save_path:\n","        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        print(f\"Plot de métricas salvo em: {save_path}\")\n","    else:\n","        plt.show()"],"metadata":{"id":"P-gzy6ksVrNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# helpers de grid/máscaras\n","def _grid_info_from_env(env_name: str, map_name: str | None = None, is_slippery: bool = False):\n","    \"\"\"\n","    Retorna (n_rows, n_cols, holes_set, cliffs_set, goals_set, start_rc)\n","    para FrozenLake-v1 ou CliffWalking-v1.\n","    \"\"\"\n","    holes, cliffs, goals = set(), set(), set()\n","    start_rc = None\n","\n","    if env_name == \"FrozenLake-v1\":\n","        kwargs = {}\n","        if map_name is not None:\n","            kwargs[\"map_name\"] = map_name\n","        kwargs[\"is_slippery\"] = is_slippery\n","\n","        env = gym.make(\"FrozenLake-v1\", **kwargs)\n","        desc = env.unwrapped.desc\n","        # decode se dtype for bytes\n","        desc = np.array(desc, dtype=str) if desc.dtype.kind != \"S\" else np.char.decode(desc, \"utf-8\")\n","        n_rows, n_cols = desc.shape\n","        for r in range(n_rows):\n","            for c in range(n_cols):\n","                ch = desc[r, c]\n","                if ch == \"H\": holes.add((r, c))\n","                elif ch == \"G\": goals.add((r, c))\n","                elif ch == \"S\": start_rc = (r, c)\n","        if start_rc is None:\n","            start_rc = (0, 0)\n","        env.close()\n","        return n_rows, n_cols, holes, cliffs, goals, start_rc\n","\n","    elif env_name == \"CliffWalking-v1\":\n","        n_rows, n_cols = 4, 12\n","        start_rc = (n_rows - 1, 0)\n","        goal_rc  = (n_rows - 1, n_cols - 1)\n","        goals.add(goal_rc)\n","        # penhasco: última linha, colunas 1..10\n","        for c in range(1, n_cols - 1):\n","            cliffs.add((n_rows - 1, c))\n","        return n_rows, n_cols, holes, cliffs, goals, start_rc\n","\n","    else:\n","        raise ValueError(\"env_name deve ser 'FrozenLake-v1' ou 'CliffWalking-v1'.\")\n","\n","def _rc_from_state(s: int, n_cols: int) -> tuple[int, int]:\n","    return divmod(s, n_cols)  # (r,c)\n","\n","# simulação de trajetória\n","def simular_trajetoria_gym(\n","    Pi: np.ndarray,\n","    env_name: str,\n","    *,\n","    map_name: str | None = None,\n","    is_slippery: bool = False,\n","    max_steps: int = 200\n","):\n","    \"\"\"\n","    Executa uma trajetória determinística (gulosa em Pi) no Gym (FrozenLake/CliffWalking).\n","    Retorna:\n","      - estados: lista de (r,c)\n","      - acoes: lista de ints\n","      - recompensas: lista de floats\n","    \"\"\"\n","    # cria env\n","    if env_name == \"FrozenLake-v1\":\n","        kwargs = {}\n","        if map_name is not None:\n","            kwargs[\"map_name\"] = map_name\n","        kwargs[\"is_slippery\"] = is_slippery\n","        env = gym.make(\"FrozenLake-v1\", **kwargs)\n","    elif env_name == \"CliffWalking-v1\":\n","        env = gym.make(\"CliffWalking-v1\")\n","    else:\n","        raise ValueError(\"env_name deve ser 'FrozenLake-v1' ou 'CliffWalking-v1'.\")\n","\n","    n_rows, n_cols, holes, cliffs, goals, start_rc = _grid_info_from_env(env_name, map_name, is_slippery)\n","\n","    # sanity check de dimensões\n","    n_states, n_actions = Pi.shape\n","    assert n_states == n_rows * n_cols, f\"Pi.shape[0]={n_states} != n_rows*n_cols={n_rows*n_cols}\"\n","    assert n_actions == env.action_space.n, f\"Pi.shape[1]={n_actions} != action_space.n={env.action_space.n}\"\n","\n","    state, _ = env.reset()\n","    # se o env permitir setar estado diretamente, tenta (FrozenLake/cliff costumam expor .unwrapped.s)\n","    if hasattr(env.unwrapped, \"s\"):\n","        env.unwrapped.s = int(state)\n","\n","    estados_rc = [_rc_from_state(int(state), n_cols)]\n","    acoes, recompensas = [], []\n","\n","    for _ in range(max_steps):\n","        s = int(state)\n","        a = int(np.argmax(Pi[s]))\n","        next_state, reward, terminated, truncated, _ = env.step(a)\n","\n","        acoes.append(a)\n","        recompensas.append(float(reward))\n","        estados_rc.append(_rc_from_state(int(next_state), n_cols))\n","\n","        state = next_state\n","        if terminated or truncated:\n","            break\n","\n","    env.close()\n","    return estados_rc, acoes, recompensas"],"metadata":{"id":"DABfiX7kK2ER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --------------------------\n","# plot da trajetória no grid\n","# --------------------------\n","def plot_trajetoria_gym(\n","    env_name: str,\n","    estados: list[tuple[int, int]],\n","    *,\n","    map_name: str | None = None,\n","    is_slippery: bool = False,\n","    titulo: str = \"Trajetória gulosa (Gym)\",\n","    gradiente_temporal: bool = True,\n","    mostrar_setas: bool = True,\n","    save_path: Optional[str] = None\n","):\n","    \"\"\"\n","    Plota a trajetória sobre um grid para FrozenLake/CliffWalking com destaques de buracos/penhasco/goal.\n","    \"\"\"\n","    n_rows, n_cols, holes, cliffs, goals, start_rc = _grid_info_from_env(env_name, map_name, is_slippery)\n","\n","    # figura/base do grid\n","    fig, ax = plt.subplots(figsize=(n_cols, n_rows))\n","    ax.set_xlim(0, n_cols); ax.set_ylim(0, n_rows)\n","    ax.set_xticks(np.arange(0, n_cols + 1, 1))\n","    ax.set_yticks(np.arange(0, n_rows + 1, 1))\n","    ax.grid(True); ax.set_aspect('equal'); ax.invert_yaxis()\n","\n","    # células coloridas\n","    for r in range(n_rows):\n","        for c in range(n_cols):\n","            cell = (r, c)\n","            if env_name == \"FrozenLake-v1\":\n","                if cell in holes:\n","                    color = (1.0, 0.0, 0.0, 0.25)  # vermelho translúcido\n","                elif cell in goals:\n","                    color = (0.0, 1.0, 0.0, 0.25)  # verde translúcido\n","                elif cell == start_rc:\n","                    color = (1.0, 1.0, 0.0, 0.18)  # amarelo leve\n","                else:\n","                    color = 'white'\n","            else:  # CliffWalking\n","                if cell in cliffs:\n","                    color = (1.0, 0.0, 0.0, 0.25)\n","                elif cell in goals:\n","                    color = (0.0, 1.0, 0.0, 0.25)\n","                elif cell == start_rc:\n","                    color = (1.0, 1.0, 0.0, 0.18)\n","                else:\n","                    color = 'white'\n","\n","            rect = patches.Rectangle((c, r), 1, 1, facecolor=color, edgecolor='gray')\n","            ax.add_patch(rect)\n","\n","    # extrai xs, ys (centros)\n","    xs = [c + 0.5 for (_, c) in estados]\n","    ys = [r + 0.5 for (r, _) in estados]\n","\n","    # linha com gradiente temporal\n","    if gradiente_temporal and len(xs) > 1:\n","        pontos = np.array([xs, ys]).T\n","        segmentos = np.stack([pontos[:-1], pontos[1:]], axis=1)\n","        lc = LineCollection(segmentos, linewidths=2.5)\n","        cores = np.linspace(0, 1, len(segmentos))\n","        lc.set_array(cores)\n","        ax.add_collection(lc)\n","        cbar = plt.colorbar(lc, ax=ax, fraction=0.046, pad=0.04)\n","        cbar.set_label(\"Progresso temporal\")\n","    else:\n","        ax.plot(xs, ys, '-o', linewidth=2.5, markersize=4)\n","\n","    # início/fim\n","    ax.scatter(xs[0], ys[0], marker='*', s=220, edgecolor='black', facecolor='yellow', zorder=5, linewidths=1.2, label='Início')\n","    ax.scatter(xs[-1], ys[-1], marker='o', s=150, edgecolor='black', facecolor='none', zorder=5, linewidths=1.2, label='Fim')\n","\n","    # setas entre células\n","    if mostrar_setas:\n","        for i in range(len(xs) - 1):\n","            dx, dy = xs[i+1] - xs[i], ys[i+1] - ys[i]\n","            ax.arrow(xs[i], ys[i], dx*0.85, dy*0.85, head_width=0.15, head_length=0.15,\n","                     length_includes_head=True, fc='black', ec='black', alpha=0.8)\n","\n","    ax.set_title(titulo)\n","    ax.legend(loc='upper right', frameon=True)\n","    plt.tight_layout()\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        print(f\"Plot da política salvo em: {save_path}\")\n","    else:\n","        plt.show()"],"metadata":{"id":"6PpD6ldhF5C9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AOeAMZ4ux_GJ"},"source":["## Algoritmo: Sarsa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZPgb5CLqLW9"},"outputs":[],"source":["def _atualiza_Pi(Pi: np.ndarray, Q: np.ndarray, s: int, eps: float) -> None:\n","    \"\"\"\n","    Deixa Pi[s, :] ε-suave em torno de argmax_a Q[s, a].\n","    \"\"\"\n","    n_acoes = Q.shape[1]\n","    a_star = int(np.argmax(Q[s]))\n","    Pi[s, :] = eps / n_acoes\n","    Pi[s, a_star] += 1.0 - eps\n","\n","def sarsa(\n","    env,\n","    gamma: float = 0.9,\n","    N: int = 500,               # episódios\n","    T: int = 200,               # passos por episódio\n","    epsilon: float = 0.1,\n","    alpha: float = 0.1,\n","    seed: Optional[int] = None\n",") -> Tuple[np.ndarray, np.ndarray, np.ndarray, int, List[int], List[float]]:\n","    \"\"\"\n","    SARSA(0) on-policy com política ε-gulosa (ε-suave) para ambientes Gymnasium de espaço discreto.\n","\n","    Parâmetros\n","    ----------\n","    env : gymnasium.Env\n","        Ambiente com observation_space/action_space do tipo Discrete.\n","    gamma : float\n","        Fator de desconto.\n","    N : int\n","        Número de episódios.\n","    eps : float\n","        Parâmetro ε da política ε-gulosa (0 ≤ ε ≤ 1).\n","    alpha : float\n","        Taxa de aprendizado.\n","    seed : int | None\n","        Semente de aleatoriedade (usada para `np.random.default_rng` e opcionalmente em `env.reset`).\n","\n","    Retorna\n","    -------\n","    Q   : np.ndarray, shape (n_states, n_actions)\n","        Estimativas finais Q(s,a).\n","    Pi  : np.ndarray, shape (n_states, n_actions)\n","        Política ε-suave resultante.\n","    numero_de_visitas : np.ndarray, shape (n_states, n_actions)\n","        Contagem de visitas por par (s,a).\n","    k   : int\n","        Número de episódios efetivamente executados (== N).\n","    episodio_T : list[int]\n","        Comprimento (passos) de cada episódio.\n","    episodio_G : list[float]\n","        Retorno (soma de recompensas não-descontadas) de cada episódio.\n","    \"\"\"\n","\n","    rng = np.random.default_rng(seed)\n","\n","    # Listas de métricas\n","    episodio_T = []\n","    episodio_G = []\n","\n","    # Atalhos\n","    n_estados  = env.observation_space.n\n","    n_acoes    = env.action_space.n\n","\n","    # Inicializações\n","    Q                 = np.zeros((n_estados, n_acoes), dtype=float)\n","    numero_de_visitas = np.zeros((n_estados, n_acoes), dtype=float)\n","\n","    # Política inicial ε-suave: uniforme\n","    Pi = np.full((n_estados, n_acoes), 1.0 / n_acoes, dtype=float)\n","\n","    # Loop episódios\n","    for k in tqdm(range(1, N + 1), desc=\"Episódios (SARSA)\", leave=True):\n","        # Reset para o estado inicial (s0)\n","        s, _ = env.reset()\n","\n","        ############################################################################\n","        # Implementação aqui\n","        # Dica:\n","        # usar\n","        # próximo estado, recompensa, terminated (flag), truncated (flag), _ = env.step(ação)\n","        # para fazer a trasição de um estado para o outro dada uma ação do agente\n","\n","        # Melhoria de politica\n","        _atualiza_Pi(Pi, Q, s, epsilon)\n","\n","        # Escolhe ação a_0 ~ Pi(s_0)\n","        a = int(rng.choice(n_acoes, p=Pi[s]))\n","\n","        # Acumuladores do episódio\n","        G = 0.0\n","\n","        # Flag de controle do laço\n","        terminated = False\n","        truncated = False\n","\n","        # Enquanto não exceder T\n","        for t in range(T):\n","\n","            # Número de visitas ao par (s,a)\n","            numero_de_visitas[s, a] += 1.0\n","\n","            # Passo no ambiente\n","            s_next, r, terminated, truncated, _ = env.step(a)\n","\n","            # Incrementa acumulador\n","            G += r\n","\n","            # Escolhe ação a_{t+1} ~ Pi(s_{t+1})\n","            _atualiza_Pi(Pi, Q, s_next, epsilon)\n","            a_next = int(rng.choice(n_acoes, p=Pi[s_next]))\n","\n","            if terminated:\n","                td_target = r\n","            else:\n","                td_target = r + gamma * Q[s_next, a_next]\n","\n","            td_error = Q[s, a] - td_target\n","            Q[s, a] -= alpha * td_error\n","\n","            # Melhoria de politica (para o estado 's' que acabamos de deixar)\n","            _atualiza_Pi(Pi, Q, s, epsilon)\n","\n","            # Avança\n","            s, a = s_next, a_next\n","\n","            # Verifica se o episódio terminou\n","            if terminated or truncated:\n","                break\n","\n","            ############################################################################\n","\n","        # Registra métricas do episódio\n","        episodio_T.append(t + 1)\n","        episodio_G.append(G)\n","\n","        ############################################################################\n","\n","    return Q, Pi, numero_de_visitas, N, episodio_T, episodio_G"]},{"cell_type":"markdown","metadata":{"id":"P2PS4lRgqLW9"},"source":["## Experimento"]},{"cell_type":"code","source":["def executar_experimento(\n","    nome_experimento: str,\n","    ambiente: str,\n","    algoritmo: callable,\n","    **kwargs\n",") -> Tuple[np.ndarray, List[int], List[float]]:\n","    \"\"\"\n","    Executa o algoritmo e retorna a política final, T e G.\n","    \"\"\"\n","    print(f\"--- Executando: {nome_experimento} ---\")\n","    env = gym.make(ambiente)\n","    try:\n","        _, Pi, _, _, T, G = algoritmo(env=env, **kwargs)\n","        return Pi, T, G\n","    finally:\n","        env.close()"],"metadata":{"id":"c-jaaL9iGmQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def executar_variacao_de_hiperparametro(\n","    nome_variacao: str,\n","    param_valores: list,\n","    algoritmo: callable,\n","    ambiente: str,\n","    output_dir: str,\n","    params_fixos: dict\n","):\n","    \"\"\"\n","    Executa variações de um hiperparâmetro,\n","    gerando plots comparativos de métricas e trajetórias individuais.\n","    \"\"\"\n","    print(f\"\\n==============================================\")\n","    print(f\"  Iniciando: Variação de {nome_variacao}\")\n","    print(f\"==============================================\\n\")\n","\n","    results_metricas = {}\n","    param_valores_sorted = sorted(list(param_valores))\n","\n","    # 1. Resultados de todas as execuções\n","    for valor in param_valores_sorted:\n","        nome_exp = f\"{nome_variacao}={valor}\"\n","        params_atuais = params_fixos.copy()\n","        chave_param = {\"EPISODIOS\": \"N\", \"ALPHA\": \"alpha\", \"GAMMA\": \"gamma\", \"EPSILON\": \"epsilon\"}[nome_variacao]\n","        params_atuais[chave_param] = valor\n","\n","        Pi, T, G = executar_experimento(\n","            nome_experimento=nome_exp,\n","            ambiente=ambiente,\n","            algoritmo=algoritmo,\n","            **params_atuais\n","        )\n","\n","        results_metricas[nome_exp] = {'T': T, 'G': G}\n","\n","        # 2. Plota a trajetória individual para cada execução\n","        estados, _, _ = simular_trajetoria_gym(Pi, ambiente, max_steps=200)\n","        plot_trajetoria_gym(\n","            ambiente,\n","            estados,\n","            titulo=f\"Trajetória (gulosa) — {nome_exp}\",\n","            save_path=f\"{output_dir}/trajetoria_{nome_exp}.pdf\"\n","        )\n","\n","    # 3. Plota comparação de métricas para a variação do hiperparâmetro\n","    plotar_comparacao_metricas(\n","        results=results_metricas,\n","        titulo_prefixo=f\"Variação de {nome_variacao}\",\n","        save_path=f\"{output_dir}/comparacao_{nome_variacao}.pdf\"\n","    )\n","    print(f\"\\n--- Variação de '{nome_variacao}' concluída. ---\")"],"metadata":{"id":"8xZhlLqdIAxK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"okxUUETkqLW_"},"source":["# Tarefa:\n","\n","1. Implemente o algoritmo Sarsa para resolver o ambiente `'CliffWalking-v1'` do [gymnasium](https://gymnasium.farama.org/environments/toy_text/cliff_walking/).\n","2. Considere os 4 hiperparametros (EPISODIOS, ALPHA, GAMMA, EPSILON)\n","    - Varie um dos hiperparametros (ex.: EPISODIOS) e fixe os demais (ex.: ALPHA, GAMMA, EPSILON).\n","        - Obs.: 3 valores para cada hiperparâmetro.\n","    - Para cada estudo de hiperparâmetro plote:\n","        - A duração do episódio por episódio\n","        - A recompensa total por episodio\n","        - Uma trajetória gulosa utilizando `plot_trajetoria_gym`.\n","    - Observação: as curvas para cada estudo de hiperparâmetro devem estar na mesma figura, isto é, se o hiperparâmetro a ser variado é o EPSILON com 3 valores, então o gráfico de duração do episódio deve mostrar as 3 curvas relativas a cada valor de EPSILON (com legenda) e de maneira similar para a recompensa total por episodio.\n","3. Repita o procedimento para cada um dos hiperparametros.\n","4. Reporte suas observações.\n","\n","**Entregáveis:**\n","\n","2. **Código** (notebook `*.ipynb`)\n","1. **Relatório** (`*.pdf`).\n","- O PDF deve conter:\n","  - **Setup** (hiperparâmetros usados).\n","  - **Resultados** (figuras e tabelas organizadas por experimento).\n","  - **Análises curtas** por experimento.\n","- O PDF **NÃO** deve conter:\n","    - Códigos."]},{"cell_type":"markdown","source":["## Hiperparâmetros Fixos"],"metadata":{"id":"2JZMB7-_M6QN"}},{"cell_type":"code","source":["params_fixos = {\n","    \"N\": 2000,\n","    \"T\": 1000,\n","    \"alpha\": 0.01,\n","    \"gamma\": 0.9,\n","    \"epsilon\": 0.3,\n","    \"seed\": 42\n","}"],"metadata":{"id":"c08Q8lq3M5wM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Baseline"],"metadata":{"id":"9FYY-ESaVzxc"}},{"cell_type":"code","source":["print(\"\\n################# EXPERIMENTO BASELINE #################\")\n","Pi_base, T_base, G_base = executar_experimento(\n","    nome_experimento=\"BASELINE\",\n","    ambiente=\"CliffWalking-v1\",\n","    algoritmo=sarsa,\n","    **params_fixos\n",")\n","\n","plotar_metricas_single(\n","    episodio_len=T_base,\n","    episodio_return=G_base,\n","    titulo=\"Métricas da Execução Baseline\",\n","    save_path=f\"{output_dir}/comparacao_BASELINE.pdf\"\n",")\n","\n","estados_base, _, _ = simular_trajetoria_gym(Pi_base, \"CliffWalking-v1\", max_steps=200)\n","plot_trajetoria_gym(\n","    \"CliffWalking-v1\",\n","    estados_base,\n","    titulo=\"Trajetória (gulosa) — BASELINE\",\n","    save_path=f\"{output_dir}/trajetoria_BASELINE.pdf\"\n",")"],"metadata":{"id":"3ZVdNUM8Vz_P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experimento 1 - Variação de EPISODIOS"],"metadata":{"id":"eZDjQEXeLrNB"}},{"cell_type":"code","source":["print(\"\\n################# EXPERIMENTO 1 #################\")\n","params_variacao_episodios = {k: v for k, v in params_fixos.items() if k != \"N\"}\n","executar_variacao_de_hiperparametro(\n","    nome_variacao=\"EPISODIOS\",\n","    param_valores=[1000, 1500, 2500, 3000],\n","    algoritmo=sarsa,\n","    ambiente=\"CliffWalking-v1\",\n","    output_dir=output_dir,\n","    params_fixos=params_variacao_episodios\n",")"],"metadata":{"id":"tjBeT1RRLlmj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experimento 2 - Variação de ALPHA"],"metadata":{"id":"YYJ54aCFLteo"}},{"cell_type":"code","source":["print(\"\\n################# EXPERIMENTO 2 #################\")\n","params_variacao_alpha = {k: v for k, v in params_fixos.items() if k != \"alpha\"}\n","executar_variacao_de_hiperparametro(\n","    nome_variacao=\"ALPHA\",\n","    param_valores=[0.0001, 0.001, 0.05, 0.1],\n","    algoritmo=sarsa,\n","    ambiente=\"CliffWalking-v1\",\n","    output_dir=output_dir,\n","    params_fixos=params_variacao_alpha\n",")"],"metadata":{"id":"GDXf-HHsLwap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experimento 3 - Variação de GAMMA"],"metadata":{"id":"IvAaVx7-Ltz_"}},{"cell_type":"code","source":["print(\"\\n################# EXPERIMENTO 3 #################\")\n","params_variacao_gamma = {k: v for k, v in params_fixos.items() if k != \"gamma\"}\n","executar_variacao_de_hiperparametro(\n","    nome_variacao=\"GAMMA\",\n","    param_valores=[0.5, 0.7, 0.95, 0.99],\n","    algoritmo=sarsa,\n","    ambiente=\"CliffWalking-v1\",\n","    output_dir=output_dir,\n","    params_fixos=params_variacao_gamma\n",")"],"metadata":{"id":"J52A0N5ELw56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experimento 4 - Variação de EPSILON"],"metadata":{"id":"Csk0mApeLuJ4"}},{"cell_type":"code","source":["print(\"\\n################# EXPERIMENTO 4 #################\")\n","params_variacao_epsilon = {k: v for k, v in params_fixos.items() if k != \"epsilon\"}\n","executar_variacao_de_hiperparametro(\n","    nome_variacao=\"EPSILON\",\n","    param_valores=[0.1, 0.2, 0.6, 0.9],\n","    algoritmo=sarsa,\n","    ambiente=\"CliffWalking-v1\",\n","    output_dir=output_dir,\n","    params_fixos=params_variacao_epsilon\n",")"],"metadata":{"id":"cMif2JSrLxOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/resultados_plots.zip /content/resultados_plots"],"metadata":{"id":"Ou6wX4SYPBqw"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["X-XapzRBJR-9","hf0af9vLqLW3","f3ahVih93jpQ","ItBdrnoWTFNc","eLfMlW3VqLW5","2JZMB7-_M6QN","IvAaVx7-Ltz_"],"provenance":[{"file_id":"1BdI8U1EH7wNU01EocGlRAY6l2k6yo4-3","timestamp":1760651494752}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}